{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T07:32:05.743624Z",
     "start_time": "2020-02-11T07:32:05.546693Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from lxml import etree\n",
    "from urllib.request import urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T07:33:01.485188Z",
     "start_time": "2020-02-11T07:33:01.482185Z"
    }
   },
   "outputs": [],
   "source": [
    "num = 1\n",
    "for page in range(10, 13): # A simple way to download many pages.\n",
    "    url = \"https://kissgoddess.com/album/30485_%d.html\" % page\n",
    "    req = requests.get(url)\n",
    "    req.encoding = 'utf-8'\n",
    "    html = req.text\n",
    "    # print(req.status_code)\n",
    "    # print(html)\n",
    "\n",
    "    tree = etree.HTML(html)\n",
    "#     print(tree)\n",
    "    result = tree.xpath('//div[@class=\"td-gallery-content\"]/img/@src')\n",
    "#     print(result)\n",
    "    for link in result:\n",
    "        print(\"download: \", link)\n",
    "        urlretrieve(link, \"E:\\crawler_pictures\\practice1\\%d.png\"%num)\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T07:33:21.926748Z",
     "start_time": "2020-02-11T07:33:21.923772Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = \"https://kissgoddess.com/album/30485.html\"\n",
    "url2 = \"https://kissgoddess.com\"\n",
    "num = 1\n",
    "for n in range(3):\n",
    "    req = requests.get(url)\n",
    "    req.encoding = 'utf-8'\n",
    "    html = req.text\n",
    "#     print(req.status_code)\n",
    "#     print(html, '\\n'*2)\n",
    "    tree = etree.HTML(html)\n",
    "    result = tree.xpath('//div[@class=\"td-gallery-content\"]/img/@src')\n",
    "#     print(result)\n",
    "    for link in result:\n",
    "        print(\"download: \", link)\n",
    "        urlretrieve(link, \"E:\\crawler_pictures\\practice1\\%d.png\"%num)\n",
    "        num += 1\n",
    "    current_page = tree.xpath('//a[@class=\"a1\"]/@href')\n",
    "    url = url2 + current_page[1] # A better way to download many pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T07:33:34.395608Z",
     "start_time": "2020-02-11T07:33:34.392138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use BeautifulSoup !!!\n",
    "url = \"https://kissgoddess.com/album/28637_2.html\"\n",
    "url2 = \"https://kissgoddess.com\"\n",
    "num = 1\n",
    "for i in range(2):\n",
    "    req = requests.get(url)\n",
    "    req.encoding = 'utf-8'\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html)\n",
    "    result = soup.find_all('div', class_=\"td-gallery-content\")\n",
    "    \n",
    "    # line 17-21 are very important\n",
    "    # the type of result is <class 'bs4.element.ResultSet'> \n",
    "    # the type of result[0] is <class 'bs4.element.Tag'> \n",
    "    # only \"Tag\" can use \".descendants\" to find next tag.\n",
    "    # sometimes the child of result includes '\\n', we must delete them.\n",
    "    child = [] \n",
    "    for child1 in result[0].descendants:  \n",
    "        child.append(child1)\n",
    "    while '\\n' in child:\n",
    "        child.remove('\\n')\n",
    "    retries = 0    \n",
    "    for i in child:\n",
    "        link = i.get('src')\n",
    "        print(\"download: \", link)\n",
    "        while retries < 3: # if failed try again, until tried three times\n",
    "#             try:\n",
    "#                 urlretrieve(link, \"E:\\crawler_pictures\\practice1\\pic%d.png\"%num)\n",
    "#                 num += 1\n",
    "            # A better way to save:\n",
    "            try:\n",
    "                pic = requests.get(link, timeout = 30) # if wait too long, give up\n",
    "                with open(\"E:\\crawler_pictures\\practice1\\pic%d.png\"%num, 'wb') as f:\n",
    "                    f.write(pic.content) \n",
    "                    # Pay attention! binary files should use \"content\" !!!\n",
    "                num += 1\n",
    "            except:\n",
    "                print(\"Download failed!\")\n",
    "                retries += 1\n",
    "            else:\n",
    "                print(\"saved!!!\")\n",
    "                break\n",
    "    page_info = soup.find_all('a', class_='a1')[1]\n",
    "    url = url2 + page_info.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T07:33:52.111533Z",
     "start_time": "2020-02-11T07:33:52.108063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use multithreading!!!\n",
    "url = \"https://kissgoddess.com/album/27471.html\"\n",
    "url2 = \"https://kissgoddess.com\"\n",
    "def download(link):\n",
    "    retries = 0\n",
    "    filename = link.split('/')[-1]\n",
    "    while retries < 3:\n",
    "        try:\n",
    "            pic = requests.get(link, timeout=40)\n",
    "            with open(\"E:\\crawler_pictures\\practice1\\%s\"%filename, 'wb') as f:\n",
    "                f.write(pic.content)\n",
    "        except:\n",
    "            print(\"Download failed!!!\")\n",
    "            retries += 1\n",
    "        else:\n",
    "            print(\"saved!!!\")\n",
    "            break\n",
    "                       \n",
    "for n in range(10):\n",
    "    req = requests.get(url)\n",
    "    req.encoding = 'utf-8'\n",
    "    html = req.text\n",
    "    tree = etree.HTML(html)\n",
    "    result = tree.xpath('//div[@class=\"td-gallery-content\"]/img/@src')\n",
    "    for link in result:\n",
    "        print(\"download: \", link)\n",
    "        t = Thread(target=download, args=(link,))\n",
    "        t.start()\n",
    "    current_page = tree.xpath('//a[@class=\"a1\"]/@href')\n",
    "    url = url2 + current_page[1] # A better way to download many pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T07:36:50.616376Z",
     "start_time": "2020-02-11T07:36:04.485450Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/0.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/001.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/002.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/003.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/004.jpg\n",
      "saved!!!\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/005.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/006.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/007.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/008.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/009.jpg\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/010.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/011.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/012.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/013.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/014.jpg\n",
      "saved!!!\n",
      "saved!!!\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/015.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/016.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/017.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/018.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/019.jpg\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/020.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/021.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/022.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/023.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/024.jpg\n",
      "saved!!!\n",
      "saved!!!\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/025.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/026.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/027.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/028.jpg\n",
      "download:  https://pic.kissgoddess.com/gallery/26454/28637/s/029.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'end'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n",
      "saved!!!\n"
     ]
    }
   ],
   "source": [
    "# Use functions\n",
    "def get_pic_links(url):\n",
    "    req = requests.get(url)\n",
    "    req.encoding = 'utf-8'\n",
    "    html = req.text\n",
    "    tree = etree.HTML(html)\n",
    "    result = tree.xpath('//div[@class=\"td-gallery-content\"]/img/@src')\n",
    "    links = []\n",
    "    for link in result:\n",
    "        links.append(link)\n",
    "    return links\n",
    "\n",
    "\n",
    "def download(link):\n",
    "    retries = 0\n",
    "    filename = link.split('/')[-1]\n",
    "    while retries < 3:\n",
    "        try:\n",
    "            pic = requests.get(link, timeout=40)\n",
    "            with open(\"E:\\crawler_pictures\\practice1\\%s\"%filename, 'wb') as f:\n",
    "                f.write(pic.content)\n",
    "        except:\n",
    "            print(\"Download failed!!!\")\n",
    "            retries += 1\n",
    "        else:\n",
    "            print(\"saved!!!\")\n",
    "            break\n",
    "            \n",
    "\n",
    "def use_multithreading(url):\n",
    "    pic_links = get_pic_links(url)\n",
    "    threads = []  \n",
    "    for link in pic_links:\n",
    "        print(\"download: \", link)\n",
    "        t = Thread(target=download, args=(link,))\n",
    "        threads.append(t)\n",
    "    for i in threads:\n",
    "        i.start()\n",
    "\n",
    "        \n",
    "def update_page(url):\n",
    "    req = requests.get(url)\n",
    "    req.encoding = 'utf-8'\n",
    "    html = req.text\n",
    "    tree = etree.HTML(html)\n",
    "    current_page = tree.xpath('//a[@class=\"a1\"]/@href')\n",
    "    url2 = url.rsplit('/', 2)[0] # use \"rsplit\" to split from back to front !!!\n",
    "    new_url = url2 + current_page[1]\n",
    "    return new_url\n",
    "\n",
    "\n",
    "def main(init_url, pages):\n",
    "    if pages < 1:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        use_multithreading(init_url)\n",
    "        new_url = update_page(init_url)\n",
    "        return main(new_url, pages-1)\n",
    "    \n",
    "init_url = \"https://kissgoddess.com/album/28637_1.html\"\n",
    "main(init_url, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
